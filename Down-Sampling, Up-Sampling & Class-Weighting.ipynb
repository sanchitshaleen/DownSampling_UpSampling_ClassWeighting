{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Down-Sampling, Up-Sampling & Class-Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import Series, DataFrame \n",
    "import pandas as pd\n",
    "%pylab inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##function Definitions\n",
    "def dnsmpl(xtrain,ytrain,p):\n",
    "    train=xtrain\n",
    "    train['y']=ytrain[0]\n",
    "    positive=train['y'].sum(axis =0)\n",
    "    negative=int(train['y'].sum(axis =0)*(1-p)/p)\n",
    "    train_0=train[train['y']==0]\n",
    "    train_1=train[train['y']==1]\n",
    "    train_0_down_sampled = train_0.sample( negative)\n",
    "    train_final=train_1.append(train_0_down_sampled)\n",
    "    return(train_final)\n",
    "    \n",
    "    \n",
    "def upsmpl(xtrain,ytrain,p):\n",
    "    train=xtrain\n",
    "    train['y']=ytrain[0]\n",
    "    negative=len(train[train['y']==0])\n",
    "    positive=train['y'].sum(axis =0)\n",
    "    replicate=int(((float(negative)+float(positive))*0.1-float(positive))/(1-0.1))\n",
    "    train_0=train[train['y']==0]\n",
    "    train_1=train[train['y']==1]\n",
    "    train_1_up_sampled = train_1.sample(replicate)\n",
    "    train_final=train.append(train_1_up_sampled,ignore_index=True)\n",
    "    \n",
    "    train_final['y'].value_counts()/len(train_final)\n",
    "    return(train_final)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter for under sampling 0.15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.15    0.817329\n",
       "0.10    0.813414\n",
       "0.20    0.764309\n",
       "0.25    0.723971\n",
       "0.30    0.697802\n",
       "dtype: float64"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Down sampling\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "scale\n",
    "lr_results={}\n",
    "for p in xrange(10,35,5):\n",
    "    p1=float(p)/float(100)\n",
    "    f1_score=[]\n",
    "    for i in xrange(1,6):\n",
    "        tr_x=\"vowel_train%s.csv\" % i\n",
    "        tr_y='vowel_tr_label%s.csv'% i\n",
    "        tst_x=\"vowel_test%s.csv\" % i\n",
    "        tst_y='vowel_tst_label%s.csv'% i\n",
    "        train_x = pd.read_csv(tr_x,header=None)\n",
    "        train_x=DataFrame(scale(train_x))\n",
    "        train_x=train_x.drop(0,1)\n",
    "        train_y=pd.read_csv(tr_y,header=None)\n",
    "        test_x=pd.read_csv(tst_x,header=None)\n",
    "        test_x=DataFrame(scale(test_x))\n",
    "        test_x=test_x.drop(0,1)\n",
    "        test_y=pd.read_csv(tst_y,header=None)\n",
    "        dwn_train=dnsmpl(train_x,train_y,p1)\n",
    "        dwn_train_y=dwn_train['y']\n",
    "        dwn_train_x=dwn_train.drop(['y'],1)\n",
    "        model = LogisticRegression()\n",
    "        result = model.fit(dwn_train_x, dwn_train_y)\n",
    "        prediction_train = model.predict(test_x)\n",
    "        f1=metrics.f1_score(test_y, prediction_train)\n",
    "        f1_score.append(f1)\n",
    "    lr_results[p1]=mean(f1_score)\n",
    "\n",
    "    \n",
    "\n",
    "lr_results1=pd.Series(lr_results) \n",
    "\n",
    "lr_results_best=lr_results1.order(ascending=False).index[0]\n",
    "print 'Best parameter for under sampling', lr_results_best \n",
    "\n",
    "lr_results1.order(ascending=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter for under sampling 0.25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.25    0.820990\n",
       "0.10    0.814216\n",
       "0.30    0.812615\n",
       "0.20    0.806641\n",
       "0.15    0.806641\n",
       "dtype: float64"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Up sampling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "lr_results={}\n",
    "for p in xrange(10,35,5):\n",
    "    p1=float(p)/float(100)\n",
    "    f1_score_up=[]\n",
    "    for i in xrange(1,6):\n",
    "        tr_x=\"vowel_train%s.csv\" % i\n",
    "        tr_y='vowel_tr_label%s.csv'% i\n",
    "        tst_x=\"vowel_test%s.csv\" % i\n",
    "        tst_y='vowel_tst_label%s.csv'% i\n",
    "        train_x = pd.read_csv(tr_x,header=None)\n",
    "        train_x=DataFrame(scale(train_x))\n",
    "        train_x=train_x.drop(0,1)\n",
    "        train_y=pd.read_csv(tr_y,header=None)\n",
    "        test_x=pd.read_csv(tst_x,header=None)\n",
    "        test_x=DataFrame(scale(test_x))\n",
    "        test_x=test_x.drop(0,1)\n",
    "        test_y=pd.read_csv(tst_y,header=None)\n",
    "        up_train=upsmpl(train_x,train_y,p1)\n",
    "        up_train_y=up_train['y']\n",
    "        up_train_x=up_train.drop(['y'],1)\n",
    "        model = LogisticRegression()\n",
    "        result = model.fit(up_train_x, up_train_y)\n",
    "        prediction_train = model.predict(test_x)\n",
    "        f1=metrics.f1_score(test_y, prediction_train)\n",
    "        f1_score_up.append(f1)\n",
    "    lr_results[p1]=mean(f1_score_up)\n",
    "\n",
    "    \n",
    "\n",
    "lr_results1=pd.Series(lr_results) \n",
    "\n",
    "lr_results_best=lr_results1.order(ascending=False).index[0]\n",
    "print 'Best parameter for under sampling', lr_results_best \n",
    "\n",
    "lr_results1.order(ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1 Score 0.814906322027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.82352941176470595,\n",
       " 0.81818181818181812,\n",
       " 0.81081081081081086,\n",
       " 0.89473684210526316,\n",
       " 0.72727272727272718]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##ClassWeighting\n",
    "weight={0:1,1:2}\n",
    "f1_score_wt=[]\n",
    "for i in xrange(1,6):\n",
    "        tr_x=\"vowel_train%s.csv\" % i\n",
    "        tr_y='vowel_tr_label%s.csv'% i\n",
    "        tst_x=\"vowel_test%s.csv\" % i\n",
    "        tst_y='vowel_tst_label%s.csv'% i\n",
    "        train_x = pd.read_csv(tr_x,header=None)\n",
    "        train_x=DataFrame(scale(train_x))\n",
    "        train_x=train_x.drop(0,1)\n",
    "        train_y=pd.read_csv(tr_y,header=None)\n",
    "        test_x=pd.read_csv(tst_x,header=None)\n",
    "        test_x=DataFrame(scale(test_x))\n",
    "        test_x=test_x.drop(0,1)\n",
    "        test_y=pd.read_csv(tst_y,header=None)\n",
    "        model = LogisticRegression(class_weight=weight)\n",
    "        result = model.fit(train_x, train_y.values)\n",
    "        prediction_train = model.predict(test_x)\n",
    "        f1=metrics.f1_score(test_y.values, prediction_train)\n",
    "        \n",
    "        f1_score_wt.append(f1)\n",
    "        \n",
    "print 'Mean F1 Score',(mean(f1_score_wt))\n",
    "\n",
    "f1_score_wt\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1 Score 0.806640530905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.75,\n",
       " 0.86486486486486491,\n",
       " 0.88235294117647056,\n",
       " 0.84848484848484851,\n",
       " 0.68750000000000011]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####Vanilla Logistic Regression\n",
    "\n",
    "f1_score_wt=[]\n",
    "for i in xrange(1,6):\n",
    "        tr_x=\"vowel_train%s.csv\" % i\n",
    "        tr_y='vowel_tr_label%s.csv'% i\n",
    "        tst_x=\"vowel_test%s.csv\" % i\n",
    "        tst_y='vowel_tst_label%s.csv'% i\n",
    "        train_x = pd.read_csv(tr_x,header=None)\n",
    "        train_x=DataFrame(scale(train_x))\n",
    "        train_x=train_x.drop(0,1)\n",
    "        train_y=pd.read_csv(tr_y,header=None)\n",
    "        test_x=pd.read_csv(tst_x,header=None)\n",
    "        test_x=DataFrame(scale(test_x))\n",
    "        test_x=test_x.drop(0,1)\n",
    "        test_y=pd.read_csv(tst_y,header=None)\n",
    "        model = LogisticRegression()\n",
    "        result = model.fit(train_x, train_y.values)\n",
    "        prediction_train = model.predict(test_x)\n",
    "        f1=metrics.f1_score(test_y.values, prediction_train)\n",
    "        \n",
    "        f1_score_wt.append(f1)\n",
    "        \n",
    "print 'Mean F1 Score',(mean(f1_score_wt))\n",
    "\n",
    "f1_score_wt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
